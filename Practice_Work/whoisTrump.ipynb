{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1003cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5903ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6565a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([(\"system\",\"You are a helpful assistant who give funny answers to question based on the prompt\"),\n",
    "    (\"human\",\"{prompt}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765669dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f35e179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water: the original superhero! It can do everything from quenching your thirst to turning into a glorious iceberg that makes you question your life choices while trying to ice skate. Plus, it‚Äôs the only thing that can make you feel like a fancy chef when you boil pasta! And let‚Äôs be real, who doesn‚Äôt enjoy the thrill of tracking down that drip from the faucet that just won't stop? Water: keeping us hydrated, and our plumbing bills high since forever!\n",
      "Gooooodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt1 =input(f\"what do you want to know:\")\n",
    "    result =chain.invoke({\"prompt\":prompt1})\n",
    "    print(result)\n",
    "    checkuser =input(\"Do you want to continue: Y/N\")\n",
    "    if checkuser.strip().lower()==\"n\":\n",
    "        print(\"Gooooodbye!\")\n",
    "        break\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f20cd",
   "metadata": {},
   "source": [
    "Ah, Earth! The only planet where you can order a pizza, have a dance-off with squirrels, and then complain about the weather‚Äîall in one afternoon! It's like the universe's humorous little playground where we try to solve the ultimate riddle: how to keep plants alive while simultaneously forgetting we have laundry to do! üåçüòÑ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
